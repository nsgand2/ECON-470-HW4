---
title: "Homework 4"
author: "Nikhita Gandhe"
date: "04/07/2025"
format: pdf
---

Please find the link to my GitHub repository here: https://github.com/nsgand2/ECON-470-HW4.git  

# Question 1

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.cap="Distribution of Plan Counts by County Over Time"}

library(tidyverse)

full_df <- read_rds("C:/Users/Nikhita Gandhe/Documents/GitHub/ECON-470-HW4/data/output/final_ma_data.rds")

q1_plot <- full_df %>%
  group_by(fips, year) %>%
  select(fips, year) %>%
  summarize(plan_count = n()) %>%
  ggplot(aes(x = as.factor(year), y = plan_count)) +
  geom_boxplot() +
  labs(
       x = "Year",
       y = "Count of Plans"
  ) +
  coord_cartesian(ylim = c(0, 40)) +  # This zooms in without dropping data
  theme_bw()

q1_plot
```




# Question 2
Provide bar graphs showing the distribution of star ratings in 2010, 2012, and 2015. How has this distribution changed over time?

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.cap="Frequency Distribution of Star Ratings by Year"}

full_df %>%
  filter(year %in% c(2010, 2012, 2015)) %>%
  filter(!is.na(Star_Rating)) %>%
  ggplot(aes(x = as.factor(Star_Rating), fill = as.factor(year))) + 
  geom_bar(position = "dodge") +
  labs(
    x = "Star Rating",
    y = "Count of Plans",
    title = "Frequency Distribution of Star Ratings by Year"
  ) + 
  theme_bw() +
  scale_fill_discrete(name = "Year")
```


# Question 3
Plot the average benchmark payment over time from 2010 through 2015. How much has the average benchmark payment risen over the years?

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.cap="Average MA Benchmark Rate Over Time"}

q3 <- full_df %>% 
  filter(year >= 2010 & year <= 2015) %>%
  group_by(year) %>%
  summarise(avg_rate = mean(ma_rate, na.rm = TRUE))

ggplot(q3, aes(x = year, y = avg_rate)) +
  geom_line() +
  geom_point() +
  labs(
    title = "Average MA Benchmark Rate Over Time",
    x = "Year",
    y = "Average MA Rate"
  ) +
  theme_minimal()
```

# Question 4
Plot the average share of Medicare Advantage (relative to all Medicare eligibles) over time from 2010 through 2015. Has Medicare Advantage increased or decreased in popularity? How does this share correlate with benchmark payments?

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.cap="Average Share of MA Enrollment Market Share (2010–2015)"}

q4 <- full_df %>% 
  filter(year >= 2010 & year <= 2015) %>%
  mutate(avg_share = avg_enrolled / avg_eligibles) %>%
  group_by(year) %>%
  summarise(avg = mean(avg_share, na.rm = TRUE)) 

ggplot(q4, aes(x = year, y = avg)) +
  geom_line() +
  geom_point() +
  labs(
    title = "Average Share of MA Enrollment Market Share (2010–2015)",
    x = "Year",
    y = "Average Share"
  ) +
  theme_minimal()
```

# Question 5
Calculate the running variable underlying the star rating. Provide a table showing the number of plans that are rounded up into a 3-star, 3.5-star, 4-star, 4.5-star, and 5-star rating.

```{r, echo=FALSE, warning=FALSE, message=FALSE}

library(tidyverse)

# Load and filter data for 2010 only
full_df10 <- full_df %>% 
  filter(year == 2010) %>%
  filter(!is.na(avg_enrollment), !is.na(partc_score)) %>%
  mutate(raw_rating = rowMeans(
    cbind(
      breastcancer_screen, rectalcancer_screen, cv_cholscreen, diabetes_cholscreen,
      glaucoma_test, monitoring, flu_vaccine, pn_vaccine, physical_health,
      mental_health, osteo_test, physical_monitor, primaryaccess,
      hospital_followup, depression_followup, nodelays, carequickly,
      overallrating_care, overallrating_plan, calltime, doctor_communicate,
      customer_service, osteo_manage, diabetes_eye, diabetes_kidney,
      diabetes_bloodsugar, diabetes_chol, antidepressant, bloodpressure,
      ra_manage, copd_test, betablocker, bladder, falling, appeals_timely,
      appeals_review
    ), na.rm = TRUE
  )) %>%
  mutate(mktshare = avg_enrolled / avg_eligibles)

# Create summarized table
star_rating_summary <- full_df10 %>%
  filter(partc_score >= 2.5) %>%
  group_by(partc_score) %>%
  summarize(count = n())

star_rating_summary
```

# Question 6
Using the RD estimator with a bandwidth of 0.125, provide an estimate of the effect of receiving a 3-star versus a 2.5 star rating on enrollments. Repeat the exercise to estimate the effects at 3.5 stars, and summarize your results in a table.

```{r, echo=FALSE}
# 2.75 cutoff (3 vs 2.5)
df_10a <- full_df10 %>%
  filter((2.75 - 0.125) <= raw_rating & raw_rating <= (2.75 + 0.125)) %>%
  mutate(raw_rating_dev = raw_rating - 2.75)

rd.est3 <- lm(avg_enrollment ~ raw_rating_dev, data = df_10a)

# 3.25 cutoff (3.5 vs 3)
df_10b <- full_df10 %>%
  filter((3.25 - 0.125) <= raw_rating & raw_rating <= (3.25 + 0.125)) %>%
  mutate(raw_rating_dev = raw_rating - 3.25)

rd.est35 <- lm(avg_enrollment ~ raw_rating_dev, data = df_10b)

# Format results
library(broom)

coef_rd3 <- tidy(rd.est3) %>% 
  select(term, estimate) %>% 
  mutate(model = "Cutoff at 2.75")

coef_rd35 <- tidy(rd.est35) %>% 
  select(term, estimate) %>% 
  mutate(model = "Cutoff at 3.25")

results_table <- bind_rows(coef_rd3, coef_rd35)

print(results_table)
```

# Question 7
Repeat your results for bandwidhts of 0.1, 0.12, 0.13, 0.14, and 0.15 (again for 3 and 3.5 stars). Show all of the results in a graph. How sensitive are your findings to the choice of bandwidth?

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.cap="Sensitivity of RD Treatment Effect to Bandwidth Choice (Cutoff at 2.75)"}

# Define bandwidths
bandwidths <- c(0.1, 0.12, 0.13, 0.14, 0.15)
results_list <- list()

# Loop over bandwidths for cutoff at 2.75
for (h in bandwidths) {
  df_band <- full_df10 %>%
    filter(abs(raw_rating - 2.75) <= h) %>%
    mutate(raw_rating_dev = raw_rating - 2.75)

  rd_model <- lm(avg_enrollment ~ raw_rating_dev, data = df_band)

  coef_data <- broom::tidy(rd_model) %>%
    filter(term == "raw_rating_dev") %>%
    mutate(
      bandwidth = h,
      lower = estimate - 1.96 * std.error,
      upper = estimate + 1.96 * std.error
    )

  results_list[[as.character(h)]] <- coef_data
}

final_results <- bind_rows(results_list)

# Plot results
ggplot(final_results, aes(x = bandwidth, y = estimate)) +
  geom_point(size = 3, color = "blue") +
  geom_line(color = "blue", alpha = 0.7) +
  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.01, color = "blue") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(
    title = "RD Treatment Effect Sensitivity to Bandwidth Choice",
    subtitle = "Cutoff at 2.75 Stars",
    x = "Bandwidth",
    y = "Estimated Treatment Effect"
  ) +
  scale_x_continuous(breaks = bandwidths) +
  theme_minimal()
```

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.cap="Sensitivity of RD Treatment Effect to Bandwidth Choice (Cutoff at 3.25)"}

# Repeat for cutoff at 3.25
results_list_b <- list()

for (h in bandwidths) {
  df_band <- full_df10 %>%
    filter(abs(raw_rating - 3.25) <= h) %>%
    mutate(raw_rating_dev = raw_rating - 3.25)

  rd_model <- lm(avg_enrollment ~ raw_rating_dev, data = df_band)

  coef_data <- broom::tidy(rd_model) %>%
    filter(term == "raw_rating_dev") %>%
    mutate(
      bandwidth = h,
      lower = estimate - 1.96 * std.error,
      upper = estimate + 1.96 * std.error
    )

  results_list_b[[as.character(h)]] <- coef_data
}

final_results_b <- bind_rows(results_list_b)

# Plot
ggplot(final_results_b, aes(x = bandwidth, y = estimate)) +
  geom_point(size = 3, color = "blue") +
  geom_line(color = "blue", alpha = 0.7) +
  geom_errorbar(aes(ymin = lower, ymax = upper), width = 0.01, color = "blue") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "red") +
  labs(
    title = "RD Treatment Effect Sensitivity to Bandwidth Choice",
    subtitle = "Cutoff at 3.25 Stars",
    x = "Bandwidth",
    y = "Estimated Treatment Effect"
  ) +
  scale_x_continuous(breaks = bandwidths) +
  theme_minimal()
```

The findings show sensitivity to bandwidth choice, particularly when comparing 3 and 3.5 stars. In contrast, estimates for the 2.5 vs. 3-star comparison remain relatively stable when the bandwidth exceeds 0.10.

# Question 8

Examine (graphically) whether contracts appear to manipulate the running variable. In other words, look at the distribution of the running variable before and after the relevent threshold values. What do you find?

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.cap="Density of Raw Ratings Around 2.75 and 3.25 Cutoffs"}

# 2.75 cutoff
kd.running30 <- full_df10 %>%
  filter((raw_rating >= 2.75 - 0.125 & Star_Rating == 2.5) | 
         (raw_rating <= 2.75 + 0.125 & Star_Rating == 3)) %>%
  ggplot(aes(x = raw_rating)) +
  geom_density(fill = "skyblue", alpha = 0.6) +
  geom_vline(xintercept = 2.75, linetype = "dashed") +
  labs(
    title = "Density Around 2.75 Rating Threshold",
    x = "Raw Rating",
    y = "Density"
  ) +
  theme_bw()

kd.running30
```

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.cap="Density of Raw Ratings Around 3.25 Cutoff"}

# 3.25 cutoff
kd.running35 <- full_df10 %>%
  filter((raw_rating >= 3.25 - 0.125 & Star_Rating == 3) | 
         (raw_rating <= 3.25 + 0.125 & Star_Rating == 3.5)) %>%
  ggplot(aes(x = raw_rating)) +
  geom_density(fill = "lightcoral", alpha = 0.6) +
  geom_vline(xintercept = 3.25, linetype = "dashed") +
  labs(
    title = "Density Around 3.25 Rating Threshold",
    x = "Raw Rating",
    y = "Density"
  ) +
  theme_bw()

kd.running35
```

There is some evidence of manipulation in the running variable near the 3.25 cutoff, as the number of plans increases sharply just above that threshold. This pattern is less pronounced around the 2.75 cutoff, where manipulation appears minimal.

# Question 9

Similar to question 4, examine whether plans just above the threshold values have different characteristics than contracts just below the threshold values. Use HMO and Part D status as your plan characteristics.

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.cap="Proportion of HMO and Part D Plans Near Cutoff (2.75 & 3.25)"}

# Prep data
df_10e <- full_df10 %>%
  mutate(plan_type_new = ifelse(plan_type %in% c("HMO/HMOPOS", "Local PPO", "Regional PPO"), 1, 0),
         partd = ifelse(partd == "Yes", 1, 0))

# Plot for 2.75 cutoff
q9_plot3 <- df_10e %>%
  filter(abs(raw_rating - 2.75) <= 0.125) %>%
  mutate(
    treat = ifelse(raw_rating >= 2.75, "Above Cutoff", "Below Cutoff"),
    hmo = factor(plan_type_new, labels = c("Non-HMO", "HMO")),
    partd = factor(partd, labels = c("No Part D", "Part D")),
    treat = factor(treat, levels = c("Below Cutoff", "Above Cutoff"))
  ) %>%
  pivot_longer(cols = c(hmo, partd), names_to = "variable", values_to = "value") %>%
  ggplot(aes(x = treat, fill = value)) +
  geom_bar(position = "fill") +
  facet_wrap(~ variable, scales = "free_y") +
  labs(
    title = "Proportion of HMO and Part D Plans Near Cutoff (2.75)",
    y = "Proportion",
    x = "",
    fill = ""
  ) +
  scale_fill_brewer(palette = "Set1") +
  theme_minimal()

q9_plot3
```

```{r, echo=FALSE, warning=FALSE, message=FALSE, fig.cap="Proportion of HMO and Part D Plans Near Cutoff (3.25)"}

# Plot for 3.25 cutoff
q9_plot35 <- df_10e %>%
  filter(abs(raw_rating - 3.25) <= 0.125) %>%
  mutate(
    treat = ifelse(raw_rating >= 3.25, "Above Cutoff", "Below Cutoff"),
    hmo = factor(plan_type_new, labels = c("Non-HMO", "HMO")),
    partd = factor(partd, labels = c("No Part D", "Part D")),
    treat = factor(treat, levels = c("Below Cutoff", "Above Cutoff"))
  ) %>%
  pivot_longer(cols = c(hmo, partd), names_to = "variable", values_to = "value") %>%
  ggplot(aes(x = treat, fill = value)) +
  geom_bar(position = "fill") +
  facet_wrap(~ variable, scales = "free_y") +
  labs(
    title = "Proportion of HMO and Part D Plans Near Cutoff (3.25)",
    y = "Proportion",
    x = "",
    fill = ""
  ) +
  scale_fill_brewer(palette = "Set1") +
  theme_minimal()

q9_plot35
```

When examining plan characteristics, there appears to be limited manipulation around the cutoffs. However, the most noticeable shift occurs at the 2.75 cutoff, where there is a significant increase in the share of HMO plans just above the threshold.

# Question 10

Summarize your findings from 5-9. What is the effect of increasing a star rating on enrollments? Briefly explain your results.

Increasing a plan’s star rating has a notable impact on enrollment, with effects varying by cutoff—enrollments can rise or fall by several hundred individuals. These estimates are sensitive to the bandwidths used in the regression analysis, particularly at the 3.25 cutoff. Additionally, plan characteristics such as HMO status and Part D coverage tend to shift around rating thresholds, suggesting that both star ratings and plan features influence enrollment patterns.